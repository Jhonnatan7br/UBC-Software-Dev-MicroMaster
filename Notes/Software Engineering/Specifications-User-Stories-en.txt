
{

  "summary": "An overview of user stories, their five key components (Role-Goal-Benefit, Limitations, Definition of Done, Tasks, Effort), and their role in agile development.",

  "keywords": ["user stories", "agile", "requirements", "role-goal-benefit", "definition of done", "effort estimate"]

}



REID HOLMES: One of the most widely used ways of actually capturing requirements

in a format that's useful for engineers and customers are user stories.

User stories are short concrete documents

that capture who a feature is for, what its value is, what's

involved in creating that feature, what its costs are,

and how long it will take to build.

These documents provide the customer a really concrete understanding

of what it is that the development team is going to do

when they're building out a future.

And they also provide a bunch of data back to the customers,

so they can understand the overall costs and trade offs

of adding a feature to their systems.

So user stories are a great way to increase

the cohesion between the customer or product owner and the development team,

and are widely used within agile methodologies.

User stories have five main parts.

So the first is called the role-goal-benefit.



So role-goal-benefit forces the customer to really think about

who is going to benefit from a feature, what they're trying to achieve,

and why they want to achieve that.

And by capturing this in a concrete way, it

gives everyone an opportunity to really think about whether or not

a feature is really worthwhile and adds real concrete value to a product.

Next, the user story will have captured the limitations of the feature.



So the limitations and clarification-- so we really

scoped down the role-goal-benefit to apply it only

in this subset of situations that matter for this feature.

The next thing we want to keep track of is known as the definition of done.



The definition of done ties exactly back to the validated requirements piece

that we were talking about earlier.

This is all about giving the development team a concrete understanding of how

the customer will be validating whether or not

the feature that they're delivering is actually done, complete, and correct.

So this is really what's going on here.

How we will be validating to make sure that the feature is complete.

Next, we keep track of engineering tasks.



These engineering tasks are mainly valuable for the development team,

as they keep track of how this feature interacts with other features

within the system or other subsystems.

And finally, we have an effort estimate.



And what the effort estimate captures is the overall cost of a feature,

and this gives the development team and customer

a concrete thing to talk about when they think about the value of a feature.

Because if it's going to take two weeks to add this feature,

but the benefit is really small, maybe this isn't actually worth doing

or not worth doing now and it's better to be left for the future.

So having this concrete effort estimate is a crucial piece of the user story

approach, as it gives the development team and customer a concrete way

to validate and think about the value of a feature versus the cost

to the technical team, as they go to build it out.

When we're thinking about user stories it's

important not to feel constrained too much by the process.

So one place that people find this constraining is

in terms of role-goal-benefit.

The role for our user stories don't always have to be human entities.

They can also be back end systems, third party servers, and other systems.

OK, so it's important to realize that that role can be non-human entities.

One other challenge with user stories is that the cost associated

with the user story always needs to be implementable

within a single iteration.

So if we are thinking what a Scrum based methodology,

that would be a single sprint typically lasting about two weeks.

The reason for this is we want to be able to go back with our user story

and get feedback from the customer really quickly.

So getting feedback after two weeks is much better

than getting feedback after a year.

One alternative implication of this is in terms of schedule slips.

So if we skip our slip--

if we doubled our schedule from a two week sprint, and it takes us a month,

that's not great.

But if we double a one year feature, and it takes two years,

that's much more impactful on the overall schedule for our product.

Now, it's really easy to do user stories badly, so what we want to do

is we want to add an additional framework here

to help us think about how to deliver user stories in an effective way.
